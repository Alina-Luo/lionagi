{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro 7 : Customization and Rate-Limited Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Session` object can be fully customized, including models, model parameters and rate limits, to accustom various usecases. \n",
    "\n",
    "Most usefully you can customize: \n",
    "\n",
    "- `service`: rate limit api service\n",
    "- `llmconfig`: the default model parameters API calls in the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, an `OpenAI` service will be provided with the default config settings:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"model\": \"gpt-4-turbo-preview\",\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": None,\n",
    "    \"n\": 1,\n",
    "    \"presence_penalty\": 0, \n",
    "    \"response_format\": {\"type\": \"text\"}, \n",
    "    \"seed\": None, \n",
    "    \"stop\": None,\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.7, \n",
    "    \"top_p\": 1, \n",
    "    \"tools\": None,\n",
    "    \"tool_choice\": \"none\", \n",
    "    \"user\": None\n",
    "    }\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to change the default behavior of a session, you can:\n",
    "- create a new api service\n",
    "- or modify llmconfig settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service\n",
    "\n",
    "lionagi currently support `OpenAI` and `OpenRouter`, and more service options are under construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick start\n",
    "from lionagi import Services, Session\n",
    "\n",
    "service_openai = Services.OpenAI()\n",
    "\n",
    "# or\n",
    "service_openrouter = Services.OpenRouter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to config the service, you can consider passing in:\n",
    "\n",
    "- `api_key`: If your API key is already stored in your environment, no explicit input is required. Otherwise, you can input your API key here.\n",
    "- `key_scheme`: By default, we assume that the environment variable storing your API key named `\"OPENAI_API_KEY\"` (or `\"OPENROUTER_API_KEY\"` for `OpenRouter`). If the variable name is different, you can specify it here. \n",
    "- `token_encoding_name`: The default `token_encoding_name` is \"cl100k_base\".\n",
    "- `max_tokens`: The maximum number of tokens allowed per interval. Default to 100000.\n",
    "- `max_requests`: The maximum number of requests allowed per interval. Default to 1000.\n",
    "- `interval`: The time interval in seconds for replenishing capacities. Default to 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we only support `chat/completions` endpoint. More endpoints will be available in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llmconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`llmconfig` can be set when creating the session or updated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example config\n",
    "# config = {\n",
    "#     'api_key': 'your_api_key_here',  # replace with your actual API key\n",
    "#     'key_scheme': 'OPENAI_API_KEY',  # or 'OPENROUTER_API_KEY' for OpenRouter\n",
    "#     'token_encoding_name': 'cl100k_base',\n",
    "#     'max_tokens': 100000,\n",
    "#     'max_requests': 1000,\n",
    "#     'interval': 60\n",
    "# }\n",
    "\n",
    "llmconfig_ = {...}  # replace with your actual config\n",
    "\n",
    "# passing in the llmconfig as a dict\n",
    "session1 = Session(\"you are a helpful assistant\", llmconfig=llmconfig_)\n",
    "\n",
    "# or\n",
    "session1.default_branch.llmconfig.update(llmconfig_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use numpy to generate random numbers for this part\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use a simple conditional calculator session as an example\n",
    "# in this example, we will have two steps in the instruction, first step would be choosing between sum or diff based on a case number\n",
    "# and second step would be choosing between times or plus based on the sign of the first step\n",
    "\n",
    "system = \"You are asked to perform as a calculator. Return only a numeric value, i.e. int or float, no text.\"\n",
    "\n",
    "instruct1 = {\n",
    "    \"sum the absolute values\": \"provided with 2 numbers, return the sum of their absolute values. i.e. |x|+|y|\",\n",
    "}\n",
    "\n",
    "instruct2 = {\n",
    "    \"diff the absolute values\": \"provided with 2 numbers, return the difference of absolute values. i.e. |x|-|y|\",\n",
    "}\n",
    "\n",
    "instruct3 = {\n",
    "    \"if previous response is positive\": \"times 2. i.e. *2\",  # case 0\n",
    "    \"else\": \"plus 2. i.e. +2\",  # case 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a case and context\n",
    "case = 0\n",
    "context = {\"x\": 7, \"y\": 3}\n",
    "instruct = instruct1 if case == 0 else instruct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 result: 10\n",
      "step2 result: 20\n",
      "run clock time: 1.88 seconds\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "calculator = Session(system)\n",
    "\n",
    "step1 = await calculator.chat(instruct, context=context)\n",
    "step2 = await calculator.chat(\n",
    "    instruct3, temperature=0.5\n",
    ")  # you can also modify parameters for each API call\n",
    "\n",
    "print(f\"step1 result: {step1}\")\n",
    "print(f\"step2 result: {step2}\")\n",
    "\n",
    "elapsed_time = timer() - start\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us run 10 senerios in parallel\n",
    "import numpy as np\n",
    "\n",
    "num_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': '-5', 'y': '9', 'case': '1'}\n",
      "{'x': '-3', 'y': '2', 'case': '1'}\n",
      "{'x': '-6', 'y': '0', 'case': '0'}\n",
      "{'x': '-10', 'y': '7', 'case': '1'}\n",
      "{'x': '-1', 'y': '0', 'case': '1'}\n",
      "{'x': '7', 'y': '0', 'case': '0'}\n",
      "{'x': '6', 'y': '8', 'case': '1'}\n",
      "{'x': '8', 'y': '8', 'case': '0'}\n",
      "{'x': '7', 'y': '8', 'case': '0'}\n",
      "{'x': '7', 'y': '6', 'case': '0'}\n"
     ]
    }
   ],
   "source": [
    "# generate random numbers\n",
    "ints1 = np.random.randint(-10, 10, size=num_iterations)\n",
    "ints2 = np.random.randint(0, 10, size=num_iterations)\n",
    "cases = np.random.randint(0, 2, size=num_iterations)\n",
    "\n",
    "\n",
    "contexts = []\n",
    "for i in range(num_iterations):\n",
    "    contexts.append({\"x\": str(ints1[i]), \"y\": str(ints2[i]), \"case\": str(cases[i])})\n",
    "\n",
    "    print(contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calculator_workflow(context):\n",
    "\n",
    "    calculator = Session(system)  # construct a session instance\n",
    "    context = context.copy()\n",
    "    case = int(context.pop(\"case\"))\n",
    "\n",
    "    instruct = instruct1 if case == 0 else instruct2\n",
    "    res1 = await calculator.chat(instruct, context=context)  # run the steps\n",
    "    res2 = await calculator.chat(instruct3, temperature=0.5)\n",
    "\n",
    "    return (res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lionagi.libs.ln_func_call as func_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_workload: 10\n",
      "run clock time: 2.00 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "outs = await func_call.alcall(contexts, calculator_workflow)\n",
    "elapsed_time = timer() - start\n",
    "print(f\"num_workload: {num_iterations}\")\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', '8'),\n",
       " ('1', '2'),\n",
       " ('6', '12'),\n",
       " ('3', '6'),\n",
       " ('1', '2'),\n",
       " ('7', '14'),\n",
       " ('-2', '0'),\n",
       " ('16', '32'),\n",
       " ('15', '30'),\n",
       " ('13', '26')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized API service concurrent calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all the session will initiate a new default service object.\n",
    "\n",
    "If you would like to have one service using across sessions, you need to pass in the **same** service object during construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Services.OpenAI(max_tokens=1000, max_requests=10, interval=10)\n",
    "\n",
    "\n",
    "async def calculator_workflow(context):\n",
    "\n",
    "    calculator = Session(system, service=service)  # construct a session instance\n",
    "    context = context.copy()\n",
    "    case = int(context.pop(\"case\"))\n",
    "    instruct = instruct1 if case == 0 else instruct2\n",
    "\n",
    "    res1 = await calculator.chat(instruct, context=context)  # run the steps\n",
    "    res2 = await calculator.chat(instruct3)\n",
    "\n",
    "    return (res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_workload: 10\n",
      "run clock time: 21.71 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "outs = await func_call.alcall(contexts, calculator_workflow)\n",
    "\n",
    "elapsed_time = timer() - start\n",
    "print(f\"num_workload: {num_iterations}\")\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', '8'),\n",
       " ('1', '2'),\n",
       " ('6', '12'),\n",
       " ('3', '6'),\n",
       " ('1', '2'),\n",
       " ('7', '14'),\n",
       " ('2', '4'),\n",
       " ('16', '32'),\n",
       " ('15', '30'),\n",
       " ('13', '26')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
