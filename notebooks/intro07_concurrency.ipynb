{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Session 2: Customization and Rate-Limited Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Session` object can be fully customized, including models, model parameters and rate limits, to accustom various usecases. \n",
    "\n",
    "Most usefully you can customize: \n",
    "\n",
    "- `service`: rate limit api service\n",
    "- `llmconfig`: the default model parameters API calls in the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, an `OpenAI` service will be provided with the default config settings:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"model\": \"gpt-4-1106-preview\",\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": None,\n",
    "    \"n\": 1,\n",
    "    \"presence_penalty\": 0, \n",
    "    \"response_format\": {\"type\": \"text\"}, \n",
    "    \"seed\": None, \n",
    "    \"stop\": None,\n",
    "    \"stream\": False,\n",
    "    \"temperature\": 0.7, \n",
    "    \"top_p\": 1, \n",
    "    \"tools\": None,\n",
    "    \"tool_choice\": \"none\", \n",
    "    \"user\": None\n",
    "    }\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to change the default behavior of a session, you can:\n",
    "- create a new api service\n",
    "- or modify llmconfig settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Service\n",
    "\n",
    "we currently support `OpenAI` and `OpenRouter`, and more service options are under construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick start\n",
    "import lionagi as li\n",
    "service_openai = li.Services.OpenAI()\n",
    "\n",
    "# or\n",
    "service_openrouter = li.Services.OpenRouter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to config the service, you can consider passing in:\n",
    "\n",
    "- `api_key`: If your API key is already stored in your environment, no explicit input is required. Otherwise, you can input your API key here.\n",
    "- `key_scheme`: By default, we assume that the environment variable storing your API key named `\"OPENAI_API_KEY\"` (or `\"OPENROUTER_API_KEY\"` for `OpenRouter`). If the variable name is different, you can specify it here. \n",
    "- `token_encoding_name`: The default `token_encoding_name` is \"cl100k_base\".\n",
    "- `max_tokens`: The maximum number of tokens allowed per interval. Default to 100000.\n",
    "- `max_requests`: The maximum number of requests allowed per interval. Default to 1000.\n",
    "- `interval`: The time interval in seconds for replenishing capacities. Default to 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we only support `chat/completions` endpoint. More endpoints will be available in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `llmconfig`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`llmconfig` can be set when creating the session or updated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmconfig_ = {...}\n",
    "\n",
    "# passing in the llmconfig as a dict \n",
    "session1 = li.Session(\"you are a helpful assistant\", llmconfig=llmconfig_)\n",
    "\n",
    "# or\n",
    "session1.llmconfig.update(llmconfig_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use numpy to generate random numbers for this part\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use a simple conditional calculator session as an example\n",
    "# in this example, we will have two steps in the instruction, first step would be choosing between sum or diff based on a case number\n",
    "# and second step would be choosing between times or plus based on the sign of the first step\n",
    "\n",
    "system = \"You are asked to perform as a calculator. Return only a numeric value, i.e. int or float, no text.\"\n",
    "\n",
    "instruct1 = {\n",
    "    \"sum the absolute values\": \"provided with 2 numbers, return the sum of their absolute values. i.e. |x|+|y|\",}\n",
    "\n",
    "instruct2 = {\n",
    "    \"diff the absolute values\": \"provided with 2 numbers, return the difference of absolute values. i.e. |x|-|y|\",}\n",
    "\n",
    "instruct3 = {\n",
    "    \"if previous response is positive\": \"times 2. i.e. *2\", # case 0\n",
    "    \"else\": \"plus 2. i.e. +2\",                              # case 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a case and context\n",
    "case = 0\n",
    "context = {\"x\": 7, \"y\": 3}\n",
    "instruct = instruct1 if case == 0 else instruct2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 result: 10\n",
      "step2 result: {\"response\": \"20\"}\n",
      "run clock time: 1.70 seconds\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "calculator = li.Session(system)\n",
    "\n",
    "step1 = await calculator.initiate(instruct, context=context)\n",
    "step2 = await calculator.followup(instruct3, temperature=0.5)     # you can also modify parameters for each API call\n",
    "\n",
    "print(f\"step1 result: {step1}\")\n",
    "print(f\"step2 result: {step2}\")\n",
    "\n",
    "elapsed_time = timer() - start\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us run 10 senerios in parallel\n",
    "import numpy as np\n",
    "\n",
    "num_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random numbers\n",
    "ints1 = np.random.randint(-10, 10, size=num_iterations)\n",
    "ints2 = np.random.randint(0, 10, size=num_iterations)\n",
    "cases = np.random.randint(0,2, size=num_iterations)\n",
    "\n",
    "# define a simple parser function\n",
    "f = lambda i: {\"x\": str(ints1[i]), \"y\": str(ints2[i]), \"case\": str(cases[i])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': '3', 'y': '4', 'case': '0'}\n",
      "{'x': '9', 'y': '9', 'case': '0'}\n",
      "{'x': '2', 'y': '3', 'case': '1'}\n",
      "{'x': '3', 'y': '1', 'case': '0'}\n",
      "{'x': '2', 'y': '6', 'case': '0'}\n",
      "{'x': '-8', 'y': '4', 'case': '0'}\n",
      "{'x': '9', 'y': '0', 'case': '1'}\n",
      "{'x': '-8', 'y': '5', 'case': '1'}\n",
      "{'x': '-10', 'y': '7', 'case': '0'}\n",
      "{'x': '1', 'y': '6', 'case': '1'}\n"
     ]
    }
   ],
   "source": [
    "contexts = li.lcall(range(num_iterations), f)\n",
    "\n",
    "li.lcall(range(num_iterations), lambda i: print(contexts[i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def calculator_workflow(context):\n",
    "    \n",
    "    calculator = li.Session(system)       # construct a session instance\n",
    "    context = context.copy()\n",
    "    case = int(context.pop(\"case\"))\n",
    "    \n",
    "    instruct = instruct1 if case == 0 else instruct2\n",
    "    res1 = await calculator.initiate(instruct, context=context)    # run the steps\n",
    "    res2 = await calculator.followup(instruct3, temperature=0.5)\n",
    "    \n",
    "    return (res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_workload: 10\n",
      "run clock time: 3.25 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "outs = await li.alcall(contexts, calculator_workflow)\n",
    "elapsed_time = timer() - start\n",
    "print(f\"num_workload: {num_iterations}\")\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7', '{\"response\": \"14\"}'),\n",
       " ('18', '{\"response\": \"36\"}'),\n",
       " ('1.0', '{\"response\": \"2.0\"}'),\n",
       " ('4', '{\"response\": \"8\"}'),\n",
       " ('8', '16'),\n",
       " ('12', '{\"response\": \"24\"}'),\n",
       " ('9.0', '18.0'),\n",
       " ('3.0', '6.0'),\n",
       " ('17', '{\"response\": \"34\"}'),\n",
       " ('-5', '{\"response\": \"-3\"}')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized API service concurrent calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all the session will initiate a new default service object.\n",
    "\n",
    "If you would like to have one service using across sessions, you need to pass in the **same** service object during construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us change the rate limit to check whether it is working\n",
    "service = li.Services.OpenAI()\n",
    "\n",
    "async def calculator_workflow(context):\n",
    "    \n",
    "    calculator = li.Session(system, service=service)       # construct a session instance\n",
    "    context = context.copy()\n",
    "    case = int(context.pop(\"case\"))\n",
    "    instruct = instruct1 if case == 0 else instruct2\n",
    "\n",
    "    res1 = await calculator.initiate(instruct, context=context)    # run the steps\n",
    "    res2 = await calculator.followup(instruct3)\n",
    "\n",
    "    return (res1, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_workload: 10\n",
      "run clock time: 4.87 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "outs = await li.alcall(contexts, calculator_workflow)  \n",
    "\n",
    "elapsed_time = timer() - start\n",
    "print(f\"num_workload: {num_iterations}\")\n",
    "print(f\"run clock time: {elapsed_time:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7', '{\"response\": \"14\"}'),\n",
       " ('18', '{\"response\": \"36\"}'),\n",
       " ('1', '2'),\n",
       " ('4', '{\"response\": \"8\"}'),\n",
       " ('8', '16'),\n",
       " ('12', '{\"response\": \"24\"}'),\n",
       " ('9.0', '18.0'),\n",
       " ('3', '6'),\n",
       " ('17', '{\"response\": \"34\"}'),\n",
       " ('-5', '-3')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
