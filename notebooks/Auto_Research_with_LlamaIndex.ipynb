{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Savior with LionAGI and LlamaIndex Vector Index\n",
    "\n",
    "-- how to do auto explorative research with LionAGI plus RAG using llamaindex Vector Index & embedding \n",
    "\n",
    "- [LionAGI](https://github.com/lion-agi/lionagi)\n",
    "- [LlamaIndex](https://www.llamaindex.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lionagi llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Large Language Model Time Series Analysis'\n",
    "dir = \"data/log/researcher/\"\n",
    "num_papers = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a Vector Index with llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader, ServiceContext, VectorStoreIndex\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArxivReader = download_loader(\"ArxivReader\")\n",
    "loader = ArxivReader()\n",
    "node_parser = SentenceSplitter(chunk_size=800, chunk_overlap=50)\n",
    "\n",
    "# let us download some papers from arvix\n",
    "documents, abstracts = loader.load_papers_and_abstracts(search_query=query, max_results=num_papers)\n",
    "nodes = node_parser.get_nodes_from_documents(documents, show_progress=False)\n",
    "\n",
    "# set up index object\n",
    "llm = OpenAI(temperature=0.1, model=\"gpt-4-1106-preview\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "index1 = VectorStoreIndex(nodes, include_embeddings=True, service_context=service_context)\n",
    "\n",
    "# set up query engine\n",
    "query_engine = index1.as_query_engine(include_text=False, response_mode=\"tree_summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tool description according to OpenAI schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lionagi as li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_arvix_papers\",\n",
    "            \"description\": \"Perform a query to a QA bot with access to a knowledge graph index built with papers from arvix\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"str_or_query_bundle\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"a question to ask the QA bot\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"str_or_query_bundle\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "func = query_engine.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = {\n",
    "    \"persona\": \"a helpful world-class researcher\",\n",
    "    \"requirements\": \"think step by step before returning a clear, precise worded answer with a humble yet confident tone\",\n",
    "    \"responsibilities\": f\"you are asked to help with researching on the topic of {query}\",\n",
    "    \"tools\": \"provided with a QA bot for grounding responses\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Research: PROMPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FORMATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliver_format1 = {\"return required\": \"yes\", \"return format\": \"paragraph\"}\n",
    "\n",
    "deliver_format2 = {\"return required\": \"yes\", \n",
    "    \"return format\": {\n",
    "        \"type\": \"json_mode\", \n",
    "        \"format\": {\n",
    "            'paper': \"paper_name\",\n",
    "            \"summary\": \"...\", \n",
    "            \"research question\": \"...\", \n",
    "            \"talking points\": {\n",
    "                \"point 1\": \"...\",\n",
    "                \"point 2\": \"...\",\n",
    "                \"point 3\": \"...\"\n",
    "            }}}},\n",
    "\n",
    "deliver_format3 = {\n",
    "    \"notice\":\"when entering each task step, identified by step number, if it is the first time that instruction is given,  you must use the tool at least once. Notice you are provided with a QA bot as your tool, the bot has access to the papers via a queriable index that takes natural language query and return a natural language answer. You can decide whether to invoke the function call, you will need to ask the bot when there are things need clarification or further information. you provide the query by asking a question, please use the tool extensively as you can\", \n",
    "    \"tool choice\": \"auto\", \n",
    "    \"format\":\"function calling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct1 = {\n",
    "    \"task step\": \"1\", \n",
    "    \"task name\": \"read paper abstracts\", \n",
    "    \"task objective\": \"get initial understanding of the papers of interest\", \n",
    "    \"task description\": \"provided with abstracts of paper, provide a brief summary highlighting the paper core points, the purpose is to extract as much information as possible\",\n",
    "    \"deliverable\": deliver_format1\n",
    "}\n",
    "\n",
    "instruct2 = {\n",
    "    \"task step\": \"2\",\n",
    "    \"task name\": \"propose research questions and talking points\", \n",
    "    \"task objective\": \"initial brainstorming\", \n",
    "    \"task description\": \"from the improved understanding of the paper, please propose an interesting, unique and practical research questions, support your reasoning. Kept on asking questions if things are not clear\",\n",
    "    \"deliverable\": deliver_format2,\n",
    "    \"function calling\": deliver_format3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Research: Setup Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = li.l_call(range(len(abstracts)), lambda i: abstracts[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def read_propose(context, num=5):\n",
    "    researcher = li.Session(system, dir=dir)\n",
    "    researcher.register_tools(tools, func)\n",
    "    \n",
    "    await researcher.initiate(instruct1, context=context, temperature=0.7)\n",
    "    await researcher.auto_followup(instruct2, tools=tools, num=num, tool_parser=lambda x: x.response)\n",
    "    \n",
    "    researcher.messages_to_csv()\n",
    "    researcher.log_to_csv()\n",
    "    return researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Research: Run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 logs saved to data/log/researcher/_messages_2023-12-14T21_27_32_206873.csv\n",
      "3 logs saved to data/log/researcher/_llmlog_2023-12-14T21_27_32_207702.csv\n",
      "8 logs saved to data/log/researcher/_messages_2023-12-14T21_27_32_311150.csv\n",
      "3 logs saved to data/log/researcher/_llmlog_2023-12-14T21_27_32_311672.csv\n",
      "8 logs saved to data/log/researcher/_messages_2023-12-14T21_27_52_174436.csv\n",
      "3 logs saved to data/log/researcher/_llmlog_2023-12-14T21_27_52_175080.csv\n",
      "8 logs saved to data/log/researcher/_messages_2023-12-14T21_27_54_939203.csv\n",
      "3 logs saved to data/log/researcher/_llmlog_2023-12-14T21_27_54_940608.csv\n",
      "8 logs saved to data/log/researcher/_messages_2023-12-14T21_28_02_312351.csv\n",
      "3 logs saved to data/log/researcher/_llmlog_2023-12-14T21_28_02_313009.csv\n"
     ]
    }
   ],
   "source": [
    "researchers = await li.al_call(abstracts, read_propose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = li.l_call(researchers, lambda x: x.conversation.messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the understanding of the paper and the potential limitations identified for LPTM, here is a proposed research question along with supporting talking points:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"paper\": \"Large Pre-trained Time Series Models for Cross-domain Time Series Analysis Tasks\",\n",
       "  \"summary\": \"The paper introduces a novel approach to time series analysis by developing a Large Pre-trained Time Series Model (LPTM) that can be applied across different domains. LPTM aims to be efficient in terms of data and computational resources, potentially reducing the amount of data and training time required to achieve state-of-the-art performance.\",\n",
       "  \"research question\": \"How can LPTM be adapted to maintain high performance when dealing with real-world time series data that is noisy, incomplete, or non-representative?\",\n",
       "  \"talking points\": {\n",
       "    \"point 1\": \"Investigating methods for noise filtering and data imputation within the LPTM framework to enhance its robustness to poor quality data.\",\n",
       "    \"point 2\": \"Exploring the potential of transfer learning techniques within LPTM to better adapt to specific real-world domains where data may be scarce or different in nature.\",\n",
       "    \"point 3\": \"Assessing the computational efficiency of LPTM in real-time applications and identifying optimization strategies for reducing latency without compromising performance.\"\n",
       "  }\n",
       "}\n",
       "```\n",
       "\n",
       "These research questions and talking points delve into practical aspects of deploying LPTM in real-world settings, where data quality and computational constraints are common issues. The aim is to examine strategies to further enhance the adaptability and efficiency of LPTM to ensure it can be effectively utilized in a variety of practical applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(out1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the information provided about Time-LLM's approach to handling data sparsity in time series forecasting through the reprogramming of large language models, I propose the following research question and talking points:\n",
       "\n",
       "**Research Question:** \n",
       "How can the reprogramming approach used by Time-LLM be extended to incorporate external domain-specific knowledge for improved forecast accuracy in highly specialized fields like finance or meteorology?\n",
       "\n",
       "**Talking Points:**\n",
       "- **Point 1:** Investigate the integration of domain-specific ontologies or knowledge graphs with Time-LLM to enhance its few-shot learning capabilities further and tailor its reasoning to industry-specific forecasting tasks.\n",
       "\n",
       "- **Point 2:** Explore the potential for Time-LLM to adapt to real-time data streams in dynamic environments, assessing the model's responsiveness and accuracy in rapidly changing conditions.\n",
       "\n",
       "- **Point 3:** Examine the transferability of Time-LLM's reprogramming framework to other types of structured data beyond time series, such as spatial or graph-based data, to understand the versatility and limitations of this approach.\n",
       "\n",
       "These talking points are designed to expand the conversation around Time-LLM's innovative approach to time series forecasting, seeking ways to optimize and broaden its application across different domains and data modalities.\n",
       "\n",
       "Should further clarification be required on any of these points, we can utilize the QA bot to query the necessary information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(out1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided summary and the practical applications of the Frozen Pretrained Transformer (FPT), an interesting research question could delve into the adaptability and transfer learning capabilities of FPT across diverse domains. It would be practical to explore how the model performs when transitioning between industries that have fundamentally different types of time series data and what fine-tuning strategies are most effective.\n",
       "\n",
       "Research Question: How can the Frozen Pretrained Transformer (FPT) be adapted for optimal performance across diverse industries with unique time series data characteristics, and what are the best practices for fine-tuning the model in these varying contexts?\n",
       "\n",
       "Talking Points:\n",
       "- **Point 1**: Investigate the impact of industry-specific data features on the performance of FPT. For example, how does the inherent noise in financial time series compare to the periodicity in energy consumption data, and what implications does this have for model fine-tuning and generalization?\n",
       "- **Point 2**: Examine the fine-tuning process of FPT when applied to industries with limited data availability. This includes exploring techniques like few-shot learning or data augmentation to enhance model performance where large datasets are not available.\n",
       "- **Point 3**: Assess the theoretical underpinnings of FPT's adaptability by studying how the model's self-attention mechanism compares to PCA in different data contexts. Understanding this relationship may provide insights into how to better leverage the model's capabilities for specific industry applications.\n",
       "\n",
       "These talking points aim to push the boundaries of understanding how FPT can be fine-tuned and applied effectively across various industries, ensuring that practitioners can harness its full potential for their specific time series analysis needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(out1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the insights from the previously mentioned limitations, we can formulate a research question and develop associated talking points.\n",
       "\n",
       "Research Question:\n",
       "How can the patched-decoder style attention model for time-series forecasting be improved to handle the nuanced grammar of time-series data and enhance its zero-shot generalization capabilities across various datasets with differing history lengths and prediction lengths?\n",
       "\n",
       "Talking Points:\n",
       "- **Point 1**: Addressing the lack of a defined vocabulary or grammar for time-series data by exploring the integration of domain-specific knowledge into the model's pretraining process. This could involve creating a synthetic 'language' of time-series data patterns and behaviors that the model could learn from.\n",
       "  \n",
       "- **Point 2**: Enhancing the model's ability to work with limited data availability by investigating techniques such as transfer learning from related time-series domains or employing data augmentation strategies to generate a more comprehensive training dataset.\n",
       "  \n",
       "- **Point 3**: Improving the flexibility and efficiency of the model with regards to varying input and output patch lengths by researching new model architectures that are inherently more adaptable to different time-series forecasting scenarios, possibly through dynamic attention mechanisms or modular design.\n",
       "  \n",
       "- **Point 4**: Developing alternative loss functions or output heads for the model that cater to both point forecasting and probabilistic forecasting, thereby expanding the model's applicability and improving its predictive performance in uncertainty quantification.\n",
       "\n",
       "- **Point 5**: Reducing the potential for error accumulation in autoregressive decoding by experimenting with non-autoregressive approaches or error correction mechanisms that could be built into the model's inference process.\n",
       "\n",
       "These talking points provide a framework for further research and development that could enhance the capabilities of large language model-inspired approaches to time-series forecasting, addressing current limitations and pushing the boundaries of what such models can achieve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(out1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the information about the Multimodal Transformer (MulT) and its potential real-world applications, here is a proposed research question and associated talking points:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"paper\": \"Multimodal Transformer for Unaligned Multimodal Language Sequences\",\n",
       "  \"summary\": \"The Multimodal Transformer (MulT) is designed to address the challenges of non-alignment and long-range dependencies in multimodal human language time-series data. Its directional pairwise crossmodal attention mechanism allows for the integration of unaligned multimodal sequences, leading to improved performance in multimodal tasks.\",\n",
       "  \"research question\": \"How can the Multimodal Transformer (MulT) be adapted to enhance communication and learning for individuals with disabilities who rely on assistive technologies that incorporate multimodal inputs?\",\n",
       "  \"talking points\": {\n",
       "    \"point 1\": \"Investigate the efficacy of MulT in real-time assistive communication devices that interpret a combination of speech, sign language, and emotional expressions.\",\n",
       "    \"point 2\": \"Explore the use of MulT in educational software that adapts to the multimodal learning patterns of students with different learning abilities, potentially improving personalized learning experiences.\",\n",
       "    \"point 3\": \"Assess the impact of MulT's crossmodal attention mechanism on the accuracy of interpreting multimodal inputs in complex environments, such as noisy classrooms or public spaces for individuals with sensory impairments.\"\n",
       "  }\n",
       "}\n",
       "```\n",
       "\n",
       "These talking points are grounded in the idea that MulT's ability to process unaligned multimodal sequences without explicit data alignment could be particularly advantageous in developing assistive technologies and educational tools for individuals with disabilities. The research question is unique and practical as it seeks to extend the application of MulT to a socially impactful area, providing benefits to a demographic that often encounters barriers to effective communication and learning. The talking points support the proposed research question by outlining specific scenarios where MulT's capabilities could be transformative. If further clarification or information is needed, I will be sure to utilize the QA bot tool provided."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(out1[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lion_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
