{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "from lionagi.libs import func_call\n",
    "from lionagi.core.prompt.prompt_template import ScoredTemplate\n",
    "from lionagi.core.branch import Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictTemplate(ScoredTemplate):\n",
    "    template_name: str = \"default_predict_template\"\n",
    "    sentence: str | list | dict = Field(\n",
    "        default_factory=str, description=\"the given sentence(s) to predict\"\n",
    "    )\n",
    "    num_sentences: int = Field(\n",
    "        default_factory=int, description=\"the number of sentences to predict\"\n",
    "    )\n",
    "    answer: str | list = Field(\n",
    "        default_factory=str, description=\"the predicted sentence(s)\"\n",
    "    )\n",
    "    signature: str = \"sentence -> answer\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence=None,\n",
    "        num_sentences=None,\n",
    "        confidence_score=False,\n",
    "        reason=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.sentence = sentence\n",
    "        self.num_sentences = num_sentences\n",
    "        self.task = f\"predict the next {self.num_sentences} sentence(s)\"\n",
    "\n",
    "        if reason:\n",
    "            self.output_fields.append(\"reason\")\n",
    "\n",
    "        if confidence_score:\n",
    "            self.output_fields.append(\"confidence_score\")\n",
    "\n",
    "\n",
    "async def predict(\n",
    "    sentence,\n",
    "    num_sentences=1,\n",
    "    confidence_score=False,\n",
    "    reason=False,\n",
    "    retries=2,\n",
    "    delay=0.5,\n",
    "    backoff_factor=2,\n",
    "    default_value=None,\n",
    "    timeout=None,\n",
    "    branch_name=None,\n",
    "    system=None,\n",
    "    messages=None,\n",
    "    service=None,\n",
    "    sender=None,\n",
    "    llmconfig=None,\n",
    "    tools=None,\n",
    "    datalogger=None,\n",
    "    persist_path=None,\n",
    "    tool_manager=None,\n",
    "    **kwargs,\n",
    "):\n",
    "\n",
    "    branch = Branch(\n",
    "        name=branch_name,\n",
    "        system=system,\n",
    "        messages=messages,\n",
    "        service=service,\n",
    "        sender=sender,\n",
    "        llmconfig=llmconfig,\n",
    "        tools=tools,\n",
    "        datalogger=datalogger,\n",
    "        persist_path=persist_path,\n",
    "        tool_manager=tool_manager,\n",
    "    )\n",
    "\n",
    "    predict_template = PredictTemplate(\n",
    "        sentence=sentence,\n",
    "        num_sentences=num_sentences,\n",
    "        confidence_score=confidence_score,\n",
    "        reason=reason,\n",
    "    )\n",
    "\n",
    "    await func_call.rcall(\n",
    "        branch.chat,\n",
    "        prompt_template=predict_template,\n",
    "        retries=retries,\n",
    "        delay=delay,\n",
    "        backoff_factor=backoff_factor,\n",
    "        default=default_value,\n",
    "        timeout=timeout,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return predict_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"a blue whale chasing a big white shark\"\n",
    "out_ = await predict(sentence, reason=True, confidence_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The shark tries to escape quickly.\n",
      "Reason:  Blue whales, being much larger, typically do not chase sharks as they feed on krill. However, in a hypothetical scenario where a blue whale is chasing a big white shark, it would likely be because the shark entered its territory, leading the shark to try to escape.\n",
      "Confidence:  0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer: \", out_.answer)\n",
    "print(\"Reason: \", out_.reason)\n",
    "print(\"Confidence: \", out_.confidence_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
