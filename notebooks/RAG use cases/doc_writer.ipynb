{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lionagi as li\n",
    "\n",
    "from pathlib import Path\n",
    "data_path = Path.cwd() / 'lionagi_data'     # Path to the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load/chunk data\n",
    "\n",
    "docs = li.load(\n",
    "    input_dir=data_path, recursive=True, required_exts=[\".py\"], \n",
    "    to_lion=False\n",
    ")\n",
    "\n",
    "docs = [i for i in docs if len(i.text)> 100]\n",
    "\n",
    "# chunks = li.chunk(\n",
    "#     docs, chunker = \"CodeSplitter\", chunker_type = \"llama_index\", \n",
    "#     to_lion=False,\n",
    "#     chunker_kwargs = {\n",
    "#         \"language\": \"python\",\n",
    "#         \"chunk_lines\": 100,\n",
    "#         \"chunk_lines_overlap\": 10,\n",
    "#         \"max_chars\": 2000,},\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_3_LARGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# index = VectorStoreIndex(chunks)\n",
    "# index.storage_context.persist(persist_dir=\"./lionagi_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage, StorageContext\n",
    "\n",
    "index_id = \"91fe61e0-89b5-4202-acff-435707e60119\"\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./lionagi_index\")\n",
    "index = load_index_from_storage(storage_context, index_id=index_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "reranker = LLMRerank(choice_batch_size=10, top_n=5)\n",
    "query_engine = index.as_query_engine(node_postprocessors=[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_codes_responses = []\n",
    "\n",
    "async def query_codebase(query):\n",
    "    \"\"\"\n",
    "    Perform a query to a QA bot with access to a vector index built with package lionagi codebase\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for in the LionAGI codebase.\n",
    "\n",
    "    Returns:\n",
    "        str: The string representation of the response content from the codebase query.\n",
    "    \"\"\"\n",
    "    response = await query_engine.aquery(query)\n",
    "    source_codes_responses.append(response)\n",
    "    return str(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=\"\"\"\n",
    "write a good API documentation for this code, make sure you use query \n",
    "engine to check meanings of code concepts to accurately describe them, \n",
    "must integrate the information from query engine to verify the correctness \n",
    "of the documentation.\n",
    "\"\"\"\n",
    "\n",
    "edit = \"\"\"\n",
    "you asked a lot of good questions and got plenty answers, please integrate your \n",
    "conversation, be a lot more technical, you will be rewarded with 500 dollars for \n",
    "great work, and punished for subpar work, take a deep breath, you can do it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PROMPTS import sys_prompt\n",
    "from lionagi.core.action import func_to_tool\n",
    "from lionagi.libs import func_call, CallDecorator as cd\n",
    "\n",
    "tools = func_to_tool(query_codebase)\n",
    "\n",
    "model = li.iModel(\n",
    "    model=\"gpt-4o\", \n",
    "    provider=\"openai\",\n",
    "    interval_tokens=5_000_000,\n",
    "    interval_requests=5_000,\n",
    "    interval=60,\n",
    ")\n",
    "\n",
    "@cd.max_concurrency(20)\n",
    "async def write_doc(context):\n",
    "    try:\n",
    "        branch = li.Branch(system=sys_prompt, tools=[query_codebase], imodel=model)\n",
    "        \n",
    "        form = await branch.direct(\n",
    "            instruction=instruction,\n",
    "            context = context,\n",
    "            reason=True,\n",
    "            score=True, \n",
    "            action_allowed=True,\n",
    "            tools=tools,\n",
    "        )\n",
    "        \n",
    "        final_doc = await branch.chat(\n",
    "            instruction=edit,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "        \n",
    "        form._add_field(\n",
    "            field=\"final_documentation\", \n",
    "            annotation = str,\n",
    "            value = final_doc,\n",
    "        )\n",
    "        \n",
    "        df = branch.to_df()\n",
    "        df.to_csv(f\"lion_doc_{branch.ln_id[:8]}.csv\", index=False)\n",
    "        \n",
    "        return form, branch\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None\n",
    "\n",
    "\n",
    "contexts = [i.text for i in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await func_call.alcall(contexts, write_doc)\n",
    "\n",
    "forms = [i[0] for i in results]\n",
    "branches = [i[1] for i in results]\n",
    "\n",
    "docs = [i.final_documentation for i in forms if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each document to a file\n",
    "for i, doc in enumerate(docs):\n",
    "    with open(f\"doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
