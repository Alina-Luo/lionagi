{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path.cwd() / \"lionagi_data\"  # Path to the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lionagi as li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare QA Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = li.load(\n",
    "    input_dir=data_path, recursive=True, required_exts=[\".py\"], to_lion=False\n",
    ")\n",
    "\n",
    "docs = [i for i in docs if len(i.text) > 100]\n",
    "\n",
    "# chunks = li.chunk(\n",
    "#     docs, chunker = \"CodeSplitter\", chunker_type = \"llama_index\",\n",
    "#     to_lion=False,\n",
    "#     chunker_kwargs = {\n",
    "#         \"language\": \"python\",\n",
    "#         \"chunk_lines\": 100,\n",
    "#         \"chunk_lines_overlap\": 10,\n",
    "#         \"max_chars\": 2000,},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_3_LARGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# index = VectorStoreIndex(chunks)\n",
    "# index.storage_context.persist(persist_dir=\"./lionagi_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_index_from_storage, StorageContext\n",
    "\n",
    "index_id = \"91fe61e0-89b5-4202-acff-435707e60119\"\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./lionagi_index\")\n",
    "index = load_index_from_storage(storage_context, index_id=index_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "reranker = LLMRerank(choice_batch_size=10, top_n=5)\n",
    "query_engine = index.as_query_engine(node_postprocessors=[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_codes_responses = []\n",
    "\n",
    "\n",
    "async def query_codebase(query):\n",
    "    \"\"\"\n",
    "    Perform a query to a QA bot with access to a vector index built with package lionagi codebase\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search for in the LionAGI codebase.\n",
    "\n",
    "    Returns:\n",
    "        str: The string representation of the response content from the codebase query.\n",
    "    \"\"\"\n",
    "    response = await query_engine.aquery(query)\n",
    "    source_codes_responses.append(response)\n",
    "    return str(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "write a good API documentation for this code, make sure you use query \n",
    "engine to check meanings of code concepts to accurately describe them, \n",
    "must integrate the information from query engine to verify the correctness \n",
    "of the documentation.\n",
    "\"\"\"\n",
    "\n",
    "edit = \"\"\"\n",
    "you asked a lot of good questions and got plenty answers, please integrate your \n",
    "conversation, be a lot more technical, you will be rewarded with 500 dollars for \n",
    "great work, and punished for subpar work, take a deep breath, you can do it\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PROMPTS import sys_prompt  # put your system prompt here\n",
    "\n",
    "tools = li.func_to_tool(query_codebase)\n",
    "\n",
    "model = li.iModel(\n",
    "    model=\"gpt-4o\",\n",
    "    provider=\"openai\",\n",
    "    interval_tokens=5_000_000,\n",
    "    interval_requests=5_000,\n",
    "    interval=60,\n",
    ")\n",
    "\n",
    "\n",
    "async def write_doc(context):\n",
    "    branch = li.Branch(system=sys_prompt, tools=[query_codebase], imodel=model)\n",
    "\n",
    "    form = await branch.direct(\n",
    "        instruction=instruction,\n",
    "        context=context,\n",
    "        reason=True,\n",
    "        score=True,\n",
    "        action_allowed=True,\n",
    "        tools=tools,\n",
    "    )\n",
    "    \n",
    "    if form is None:\n",
    "        return None, None\n",
    "\n",
    "    final_doc = await branch.chat(\n",
    "        instruction=edit,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    form._add_field(\"final_documentation\", value=final_doc)\n",
    "\n",
    "    # save all messages into a unique file\n",
    "    df = branch.to_df()\n",
    "    df.to_csv(f\"lion_doc_{branch.ln_id[:8]}.csv\", index=False)\n",
    "\n",
    "    return form, branch\n",
    "\n",
    "\n",
    "contexts = [i.text for i in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await write_doc(contexts[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**task**: \n",
       " Follow the prompt and provide the necessary output.\n",
       "- Additional instruction: \n",
       "write a good API documentation for this code, make sure you use query \n",
       "engine to check meanings of code concepts to accurately describe them, \n",
       "must integrate the information from query engine to verify the correctness \n",
       "of the documentation.\n",
       "\n",
       "- Additional context: import asyncio\n",
       "from pydantic import Field\n",
       "\n",
       "from lionagi.core.mail.mail import Mail, Package\n",
       "from lionagi.core.collections import Exchange\n",
       "from lionagi.core.mail.mail_manager import MailManager\n",
       "from lionagi.core.execute.base_executor import BaseExecutor\n",
       "from lionagi.core.execute.branch_executor import BranchExecutor\n",
       "\n",
       "\n",
       "class InstructionMapExecutor(BaseExecutor):\n",
       "    \"\"\"\n",
       "    Manages the execution of a mapped set of instructions across multiple branches within an executable structure.\n",
       "\n",
       "    Attributes:\n",
       "        branches (dict[str, BranchExecutor]): A dictionary of branch executors managing individual instruction flows.\n",
       "        structure_id (str): The identifier for the structure within which these branches operate.\n",
       "        mail_transfer (Exchange): Handles the transfer of mail between branches and other components.\n",
       "        branch_kwargs (dict): Keyword arguments used for initializing branches.\n",
       "        num_end_branches (int): Tracks the number of branches that have completed execution.\n",
       "        mail_manager (MailManager): Manages the distribution and collection of mails across branches.\n",
       "    \"\"\"\n",
       "\n",
       "    branches: dict[str, BranchExecutor] = Field(\n",
       "        default_factory=dict, description=\"The branches of the instruction mapping.\"\n",
       "    )\n",
       "    structure_id: str = Field(\"\", description=\"The ID of the executable structure.\")\n",
       "    mail_transfer: Exchange = Field(\n",
       "        default_factory=Exchange, description=\"The mail transfer.\"\n",
       "    )\n",
       "    branch_kwargs: dict = Field(\n",
       "        default_factory=dict,\n",
       "        description=\"The keyword arguments for the initializing the branches.\",\n",
       "    )\n",
       "    num_end_branches: int = Field(0, description=\"The number of end ..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**reason**: \n",
       " Let's think step by step. The provided code defines a class `InstructionMapExecutor` that manages the execution of instructions across multiple branches. The class has several attributes and methods that handle the initialization, processing of incoming and outgoing mails, and continuous execution of the instruction map. The documentation provides a clear and detailed description of each attribute and method, including their parameters and functionality. This ensures that developers can easily understand and use the `InstructionMapExecutor` class."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**score**: 9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**tool_used**: ['query_codebase']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**answer**: \n",
       " ```markdown\n",
       "## Class: `InstructionMapExecutor`\n",
       "\n",
       "**Description**:\n",
       "`InstructionMapExecutor` manages the execution of a mapped set of instructions across multiple branches within an executable structure. It handles the distribution and collection of mails, initializes branch executors, and processes incoming and outgoing mails to ensure proper execution flow.\n",
       "\n",
       "### Attributes:\n",
       "- `branches` (dict[str, BranchExecutor]): A dictionary of branch executors managing individual instruction flows.\n",
       "- `structure_id` (str): The identifier for the structure within which these branches operate.\n",
       "- `mail_transfer` (Exchange): Handles the transfer of mail between branches and other components.\n",
       "- `branch_kwargs` (dict): Keyword arguments used for initializing branches.\n",
       "- `num_end_branches` (int): Tracks the number of branches that have completed execution.\n",
       "- `mail_manager` (MailManager): Manages the distribution and collection of mails across branches.\n",
       "\n",
       "### Methods:\n",
       "\n",
       "#### `__init__(self, **kwargs)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def __init__(self, **kwargs):\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `**kwargs`: Arbitrary keyword arguments passed to the base executor and used for initializing branch executors.\n",
       "\n",
       "**Description**:\n",
       "Initializes an `InstructionMapExecutor` with the given parameters.\n",
       "\n",
       "#### `transfer_ins(self)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def transfer_ins(self):\n",
       "```\n",
       "\n",
       "**Description**:\n",
       "Processes incoming mails, directing them appropriately based on their categories, and handles the initial setup of branches or the routing of node and condition mails.\n",
       "\n",
       "#### `transfer_outs(self)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def transfer_outs(self):\n",
       "```\n",
       "\n",
       "**Description**:\n",
       "Processes outgoing mails from the central mail transfer, handling end-of-execution notifications and routing other mails to appropriate recipients.\n",
       "\n",
       "#### `_process_start(self, start_mail: Mail)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def _process_start(self, start_mail: Mail):\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `start_mail` (Mail): The mail initiating the start of a new branch execution.\n",
       "\n",
       "**Description**:\n",
       "Processes a start mail to initialize a new branch executor and configures it based on the mail's package content.\n",
       "\n",
       "#### `_process_node_list(self, nl_mail: Mail)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def _process_node_list(self, nl_mail: Mail):\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `nl_mail` (Mail): The mail containing a list of nodes to be processed in subsequent branches.\n",
       "\n",
       "**Description**:\n",
       "Processes a node list mail, setting up new branches or propagating the execution context based on the node list provided in the mail.\n",
       "\n",
       "#### `forward(self)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "async def forward(self):\n",
       "```\n",
       "\n",
       "**Description**:\n",
       "Forwards the execution by processing all incoming and outgoing mails and advancing the state of all active branches.\n",
       "\n",
       "#### `execute(self, refresh_time=1)`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "async def execute(self, refresh_time=1):\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `refresh_time` (int): The time in seconds between execution cycles.\n",
       "\n",
       "**Description**:\n",
       "Continuously executes the forward process at specified intervals until instructed to stop.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "form.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b845c535d325405357327a48e7287278</td>\n",
       "      <td>System</td>\n",
       "      <td>2024-05-22T19:49:13.320516</td>\n",
       "      <td>system</td>\n",
       "      <td>{'system_info': '\n",
       "you are a helpful assistant,...</td>\n",
       "      <td>{'last_updated': {'recipient': '2024-05-22T19:...</td>\n",
       "      <td>system</td>\n",
       "      <td>c7af4431fe3bad5d7aaf656fd9dce57d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8706accd8b7dd948857987d172258951</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2024-05-22T19:49:13.321295</td>\n",
       "      <td>user</td>\n",
       "      <td>{'instruction': '\n",
       "        ## Task Instructions...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-05-22T19:49:...</td>\n",
       "      <td>user</td>\n",
       "      <td>c7af4431fe3bad5d7aaf656fd9dce57d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003da7b75bb1c3d6fb5061540d1d35a</td>\n",
       "      <td>AssistantResponse</td>\n",
       "      <td>2024-05-22T19:49:29.725628</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-05-22T19:49:...</td>\n",
       "      <td>c7af4431fe3bad5d7aaf656fd9dce57d</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d7f560e69afa86a5301cf5dafb5e766b</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2024-05-22T19:49:29.727464</td>\n",
       "      <td>user</td>\n",
       "      <td>{'instruction': '\n",
       "you asked a lot of good ques...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-05-22T19:49:...</td>\n",
       "      <td>user</td>\n",
       "      <td>c7af4431fe3bad5d7aaf656fd9dce57d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8563163746aa0440f89c98ddc273c162</td>\n",
       "      <td>AssistantResponse</td>\n",
       "      <td>2024-05-22T19:49:54.677814</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-05-22T19:49:...</td>\n",
       "      <td>c7af4431fe3bad5d7aaf656fd9dce57d</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ln_id       message_type  \\\n",
       "0  b845c535d325405357327a48e7287278             System   \n",
       "1  8706accd8b7dd948857987d172258951        Instruction   \n",
       "2  0003da7b75bb1c3d6fb5061540d1d35a  AssistantResponse   \n",
       "3  d7f560e69afa86a5301cf5dafb5e766b        Instruction   \n",
       "4  8563163746aa0440f89c98ddc273c162  AssistantResponse   \n",
       "\n",
       "                    timestamp       role  \\\n",
       "0  2024-05-22T19:49:13.320516     system   \n",
       "1  2024-05-22T19:49:13.321295       user   \n",
       "2  2024-05-22T19:49:29.725628  assistant   \n",
       "3  2024-05-22T19:49:29.727464       user   \n",
       "4  2024-05-22T19:49:54.677814  assistant   \n",
       "\n",
       "                                             content  \\\n",
       "0  {'system_info': '\n",
       "you are a helpful assistant,...   \n",
       "1  {'instruction': '\n",
       "        ## Task Instructions...   \n",
       "2  {'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...   \n",
       "3  {'instruction': '\n",
       "you asked a lot of good ques...   \n",
       "4  {'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'last_updated': {'recipient': '2024-05-22T19:...   \n",
       "1  {'last_updated': {'sender': '2024-05-22T19:49:...   \n",
       "2  {'last_updated': {'sender': '2024-05-22T19:49:...   \n",
       "3  {'last_updated': {'sender': '2024-05-22T19:49:...   \n",
       "4  {'last_updated': {'sender': '2024-05-22T19:49:...   \n",
       "\n",
       "                             sender                         recipient  \n",
       "0                            system  c7af4431fe3bad5d7aaf656fd9dce57d  \n",
       "1                              user  c7af4431fe3bad5d7aaf656fd9dce57d  \n",
       "2  c7af4431fe3bad5d7aaf656fd9dce57d                              user  \n",
       "3                              user  c7af4431fe3bad5d7aaf656fd9dce57d  \n",
       "4  c7af4431fe3bad5d7aaf656fd9dce57d                              user  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the workflow across all contexts with a maximum of 20 concurrent processes\n",
    "# results = await li.alcall(contexts[20:25], write_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = form.final_documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([docs]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not dict"
     ]
    }
   ],
   "source": [
    "# save each document to a file\n",
    "for i, doc in enumerate([docs]):\n",
    "    with open(f\"doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
